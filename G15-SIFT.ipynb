{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7cce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import all, any, array, arctan2, cos, sin, exp, dot, log, logical_and, roll, sqrt, stack, trace, unravel_index, pi, deg2rad, rad2deg, where, zeros, floor, full, nan, isnan, round, float32\n",
    "from numpy.linalg import det, lstsq, norm\n",
    "from functools import cmp_to_key\n",
    "import cv2\n",
    "from cv2 import resize, GaussianBlur, subtract, KeyPoint, INTER_LINEAR, INTER_NEAREST\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac6152",
   "metadata": {},
   "source": [
    "## Global Variables ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3861782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines the length of floats the SIFT function will tolerate\n",
    "float_tolerance = 1e-7\n",
    "\n",
    "# Determines whether to run SIFT in verbose mode\n",
    "# (Prints out messages for debugging)\n",
    "VERBOSE_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd61517",
   "metadata": {},
   "source": [
    "# SIFT Implementation #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6941d",
   "metadata": {},
   "source": [
    "Please note: This implementation is largely based on the one originally created by Russ Islam, which can be found here:\n",
    "https://github.com/rmislam/PythonSIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4032b",
   "metadata": {},
   "source": [
    "## Image Pyramid Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad37ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the base image from the given input image\n",
    "# by upsampling by 2 in both directions and then applying\n",
    "# a Gaussian blur.\n",
    "def generateBaseImage(image, sigma, assumed_blur):\n",
    "    image = resize(image, (0, 0), fx=2, fy=2, interpolation=INTER_LINEAR)\n",
    "    sigma_diff = sqrt(max((sigma ** 2) - ((2 * assumed_blur) ** 2), 0.01))\n",
    "    \n",
    "    # The image blur is now sigma instead of assumed_blur\n",
    "    return GaussianBlur(image, (0, 0), sigmaX=sigma_diff, sigmaY=sigma_diff)  \n",
    "\n",
    "# Compute number of octaves in the image pyramid based\n",
    "# on the original OpenCV implementation.\n",
    "# (Function of base image shape)\n",
    "def computeOctaves(img_shape):\n",
    "    return int(round(log(min(img_shape)) / log(2)-1))\n",
    "\n",
    "# Generate a list of Gaussian Kernels at which to blur the image\n",
    "# Default values of sigma, intervals, and octaves are based on section 3\n",
    "# of David G. Lowe's paper.\n",
    "def generateGaussianKernels(sigma, intervals):\n",
    "    # Set number of intervals\n",
    "    images_per_octave = intervals + 3\n",
    "    k = 2 ** (1.0 / intervals) # Normalise\n",
    "    \n",
    "    # Scale of gaussian blur necessary to go from one blur scale to the next within an octave\n",
    "    gaussian_kernels = zeros(images_per_octave)\n",
    "    gaussian_kernels[0] = sigma\n",
    "\n",
    "    # For each image, work out the appropriate sigma value\n",
    "    for image_index in range(1, images_per_octave):\n",
    "        sigma_previous = (k ** (image_index - 1)) * sigma\n",
    "        sigma_total = k * sigma_previous\n",
    "        gaussian_kernels[image_index] = sqrt(sigma_total ** 2 - sigma_previous ** 2)\n",
    "    return gaussian_kernels\n",
    "\n",
    "# Generate the scale-space pyramid of Gaussian Images\n",
    "# See: Lecture 7 - Page 14\n",
    "def generateGaussianImages(img, octaves, kernels):\n",
    "    \n",
    "    gaussian_images = []\n",
    "    \n",
    "    for octave_index in range(octaves):\n",
    "        gaussian_images_in_octave = []\n",
    "        # First image in pyramid already has the correct blur\n",
    "        gaussian_images_in_octave.append(img)\n",
    "        \n",
    "        # Blur each image\n",
    "        for kernel in kernels[1:]:\n",
    "            #print(kernel) DEBUG\n",
    "            #img = gaussian_blur(img, 1, kernel) # ORIGINALLY 0\n",
    "            img = GaussianBlur(img, (0, 0), sigmaX=kernel, sigmaY=kernel)\n",
    "            gaussian_images_in_octave.append(img)\n",
    "        \n",
    "        # Append images to master array\n",
    "        gaussian_images.append(gaussian_images_in_octave)\n",
    "        octave_base = gaussian_images_in_octave[-3]\n",
    "        \n",
    "        # Resize image\n",
    "        img = resize(octave_base, (int(octave_base.shape[1] / 2), int(octave_base.shape[0] / 2)), interpolation=INTER_NEAREST)\n",
    "    \n",
    "    return array(gaussian_images, dtype=object)\n",
    "\n",
    "# Generate a Difference of Gaussian (DoG) image pyramid\n",
    "def generateDoGImages(gaussian_images):\n",
    "    \n",
    "    dog_images = []\n",
    "    \n",
    "    # Similar process to latter function\n",
    "    for gaussian_images_in_octave in gaussian_images:\n",
    "        dog_images_in_octave = []\n",
    "        \n",
    "        for first_image, second_image in zip(gaussian_images_in_octave, gaussian_images_in_octave[1:]):\n",
    "            # Ordinary subtraction will not work because the images are unsigned integers\n",
    "            dog_images_in_octave.append(subtract(second_image, first_image))\n",
    "        \n",
    "        dog_images.append(dog_images_in_octave)\n",
    "        \n",
    "    return array(dog_images, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48e4e3",
   "metadata": {},
   "source": [
    "## Scale Space Extrema Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8637f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the pixel positions of all Scale-Space Extrema in the image pyramid\n",
    "def findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width, contrast_threshold=0.04):\n",
    "\n",
    "    # From OpenCV implementation\n",
    "    threshold = floor(0.5 * contrast_threshold / num_intervals * 255)  \n",
    "    keypoints = []\n",
    "\n",
    "    for octave_index, dog_images_in_octave in enumerate(dog_images):\n",
    "        for image_index, (first_image, second_image, third_image) in enumerate(zip(dog_images_in_octave, dog_images_in_octave[1:], dog_images_in_octave[2:])):\n",
    "            # (i, j) is the center of the 3x3 array\n",
    "            for i in range(image_border_width, first_image.shape[0] - image_border_width):\n",
    "                for j in range(image_border_width, first_image.shape[1] - image_border_width):\n",
    "                    # Checks for extrenum values\n",
    "                    if isPixelAnExtremum(first_image[i-1:i+2, j-1:j+2], second_image[i-1:i+2, j-1:j+2], third_image[i-1:i+2, j-1:j+2], threshold):\n",
    "                        localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width)\n",
    "                        if localization_result is not None:\n",
    "                            keypoint, localized_image_index = localization_result\n",
    "                            keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, octave_index, gaussian_images[octave_index][localized_image_index])\n",
    "                            for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                                keypoints.append(keypoint_with_orientation)\n",
    "    return keypoints\n",
    "\n",
    "# Returns true if the centre element of the 3x3x3 input array is strictly greater\n",
    "# than or less than all of its neighbours, and false otherwise\n",
    "def isPixelAnExtremum(first_subimage, second_subimage, third_subimage, threshold):\n",
    "  centre_pixel_value = second_subimage[1,1]\n",
    "\n",
    "  # Checks if pixel value is above the given threshold\n",
    "  if abs(centre_pixel_value) > threshold:\n",
    "    if centre_pixel_value > 0:\n",
    "      # Check pixel against its neighbours\n",
    "      return all(centre_pixel_value >= first_subimage) and \\\n",
    "                   all(centre_pixel_value >= third_subimage) and \\\n",
    "                   all(centre_pixel_value >= second_subimage[0, :]) and \\\n",
    "                   all(centre_pixel_value >= second_subimage[2, :]) and \\\n",
    "                   centre_pixel_value >= second_subimage[1,0] and \\\n",
    "                   centre_pixel_value >= second_subimage[1,2]\n",
    "    elif centre_pixel_value < 0:\n",
    "        return all(centre_pixel_value <= first_subimage) and \\\n",
    "                all(centre_pixel_value <= third_subimage) and \\\n",
    "                all(centre_pixel_value <= second_subimage[0, :]) and \\\n",
    "                all(centre_pixel_value <= second_subimage[2, :]) and \\\n",
    "                centre_pixel_value <= second_subimage[1,0] and \\\n",
    "                centre_pixel_value <= second_subimage[1,2]\n",
    "  return False\n",
    "\n",
    "# Iteratively refine pixel positions of Scale Space extrema\n",
    "# via quadratic fit around each extremum's neighbors\n",
    "def localizeExtremumViaQuadraticFit(i, j, image_index, octave_index, intervals, dog_images_in_octave, \n",
    "                                    sigma, contrast_threshold, image_border_width, \n",
    "                                    eigenvalue_ratio=10, attempts_until_convergence=5):\n",
    "  extremum_is_outside_image = False\n",
    "  image_shape = dog_images_in_octave[0].shape\n",
    "\n",
    "  for attempt_index in range(attempts_until_convergence):\n",
    "    # We need to convert from uint8 to float32 to compute derivatives\n",
    "    # after which we need to rescale pixel values to [0, 1] to apply Lowe's thresholds\n",
    "    first_image, second_image, third_image = dog_images_in_octave[image_index-1:image_index+2]\n",
    "    pixel_cube = stack([first_image[i-1:i+2, j-1:j+2],\n",
    "                        second_image[i-1:i+2, j-1:j+2],\n",
    "                        third_image[i-1:i+2, j-1:j+2]]).astype('float32') / 255.\n",
    "    # Compute the gradient and hessian values\n",
    "    gradient = computeGradientAtCentrePixel(pixel_cube)\n",
    "    hessian = computeHessianAtCentrePixel(pixel_cube)\n",
    "\n",
    "    # Compute the least-squares solution of the hessian and the gradient matrices\n",
    "    extremum_update = -lstsq(hessian, gradient, rcond=None)[0]\n",
    "    if abs(extremum_update[0]) < 0.5 and abs(extremum_update[1]) < 0.5 and abs(extremum_update[2]) < 0.5:\n",
    "        break\n",
    "    j += int(round(extremum_update[0]))\n",
    "    i += int(round(extremum_update[1]))\n",
    "    image_index += int(round(extremum_update[2]))\n",
    "\n",
    "    # Make sure the new pixel_cube will lie entirely within the image\n",
    "    if i < image_border_width or i >= image_shape[0] - image_border_width or j < image_border_width or j >= image_shape[1] - image_border_width or image_index < 1 or image_index > intervals:\n",
    "        extremum_is_outside_image = True\n",
    "        break\n",
    "\n",
    "  # Logging functions\n",
    "  if extremum_is_outside_image:\n",
    "      #logger.debug('Updated extremum moved outside of image before reaching convergence. Skipping...')\n",
    "      return None\n",
    "  if attempt_index >= attempts_until_convergence - 1:\n",
    "      #logger.debug('Exceeded maximum number of attempts without reaching convergence for this extremum. Skipping...')\n",
    "      return None\n",
    "\n",
    "  functionValueAtUpdatedExtremum = pixel_cube[1, 1, 1] + 0.5 * dot(gradient, extremum_update)\n",
    "  if abs(functionValueAtUpdatedExtremum) * intervals >= contrast_threshold:\n",
    "      xy_hessian = hessian[:2, :2]\n",
    "      xy_hessian_trace = trace(xy_hessian)\n",
    "      xy_hessian_det = det(xy_hessian)\n",
    "      if xy_hessian_det > 0 and eigenvalue_ratio * (xy_hessian_trace ** 2) < ((eigenvalue_ratio + 1) ** 2) * xy_hessian_det:\n",
    "          # Contrast check passed -- construct and return OpenCV KeyPoint object\n",
    "          # MAKE OWN KEYPOINT^^^\n",
    "          keypoint = KeyPoint()\n",
    "          keypoint.pt = ((j + extremum_update[0]) * (2 ** octave_index), (i + extremum_update[1]) * (2 ** octave_index))\n",
    "          keypoint.octave = octave_index + image_index * (2 ** 8) + int(round((extremum_update[2] + 0.5) * 255)) * (2 ** 16)\n",
    "          # Octave_index + 1 because the input image was doubled\n",
    "          keypoint.size = sigma * (2 ** ((image_index + extremum_update[2]) / float32(intervals))) * (2 ** (octave_index + 1)) \n",
    "          keypoint.response = abs(functionValueAtUpdatedExtremum)\n",
    "          return keypoint, image_index\n",
    "  return None\n",
    "\n",
    "# Approximate the gradient at the centre pixel (of 3x3x3 array)\n",
    "# by using the \"Central Difference\" formula (Order: O(h^2))\n",
    "# See: https://learn.lboro.ac.uk/archive/olmp/olmp_resources/pages/workbooks_1_50_jan2008/Workbook31/31_3_num_diff.pdf\n",
    "def computeGradientAtCentrePixel(pixel_array):\n",
    "  # Central Difference formula considering h (step size) of order O(h^2) for f'(x) \n",
    "  # is (f(x + h) - f(x - h)) / (2 * h)\n",
    "  # Since h=1 in this case, we get: f'(x) = (f(x + 1) - f(x - 1)) / 2\n",
    "  # NOTE: x corresponds to second array axis, y corresponds to first array axis, and s (scale) corresponds to third array axis\n",
    "  dx = 0.5 * (pixel_array[1, 1, 2] - pixel_array[1, 1, 0])\n",
    "  dy = 0.5 * (pixel_array[1, 2, 1] - pixel_array[1, 0, 1])\n",
    "  ds = 0.5 * (pixel_array[2, 1, 1] - pixel_array[0, 1, 1])\n",
    "\n",
    "  return array([dx, dy, ds])\n",
    "\n",
    "# Same principles as the function above\n",
    "def computeHessianAtCentrePixel(pixel_array):\n",
    "  \n",
    "  # Central Difference formula considering h (step size) of order O(h^2) for \n",
    "  # (d^2) f(x, y) / (dx dy) = (f(x + h, y + h) - f(x + h, y - h) - f(x - h, y + h) + f(x - h, y - h)) / (4 * h ^ 2)\n",
    "  # Since h=1 in this case, we get: \n",
    "  # (d^2) f(x, y) / (dx dy) = (f(x + 1, y + 1) - f(x + 1, y - 1) - f(x - 1, y + 1) + f(x - 1, y - 1)) / 4\n",
    "  \n",
    "  centre_pixel_value = pixel_array[1,1,1]\n",
    "\n",
    "  dxx = pixel_array[1,1,2] - 2 * centre_pixel_value + pixel_array[1,1,0]\n",
    "  dyy = pixel_array[1,2,1] - 2 * centre_pixel_value + pixel_array[1,0,1]\n",
    "  dss = pixel_array[2,1,1] - 2 * centre_pixel_value + pixel_array[0,1,1]\n",
    "\n",
    "  dxy = 0.25 * (pixel_array[1,2,2] - pixel_array[1,2,0] - pixel_array[1,0,2] + pixel_array[1,0,0])\n",
    "  dxs = 0.25 * (pixel_array[2,1,2] - pixel_array[2,1,0] - pixel_array[0,1,2] + pixel_array[0,1,0])\n",
    "  dys = 0.25 * (pixel_array[2,2,1] - pixel_array[2,0,1] - pixel_array[0,2,1] + pixel_array[0,0,1])\n",
    "  return array([[dxx, dxy, dxs], \n",
    "              [dxy, dyy, dys],\n",
    "              [dxs, dys, dss]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6367c2",
   "metadata": {},
   "source": [
    "## Keypoint Orientation Function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5806f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the orientations of each keypoint\n",
    "def computeKeypointsWithOrientations(keypoint, octave_index, gaussian_image, radius_factor=3, \n",
    "                                     num_bins=36, peak_ratio=0.8, scale_factor=1.5):\n",
    "  keypoints_with_orientations = []\n",
    "  image_shape = gaussian_image.shape\n",
    "\n",
    "  # Comparison with keypoint.size computation in \"localizeExtremumViaQuadraticFit()\"\n",
    "  scale = scale_factor * keypoint.size / float32(2 ** (octave_index + 1))\n",
    "\n",
    "  # Prepare histogram values\n",
    "  radius = int(round(radius_factor * scale))\n",
    "  weight_factor = -0.5 / (scale ** 2)\n",
    "  raw_histogram = zeros(num_bins)\n",
    "  smooth_histogram = zeros(num_bins)\n",
    "\n",
    "  # Go through the Y-range\n",
    "  for i in range(-radius, radius + 1):\n",
    "        region_y = int(round(keypoint.pt[1] / float32(2 ** octave_index))) + i\n",
    "        if region_y > 0 and region_y < image_shape[0] - 1:\n",
    "            # Go through the X-range\n",
    "            for j in range(-radius, radius + 1):\n",
    "                region_x = int(round(keypoint.pt[0] / float32(2 ** octave_index))) + j\n",
    "                if region_x > 0 and region_x < image_shape[1] - 1:\n",
    "                    dx = gaussian_image[region_y, region_x + 1] - gaussian_image[region_y, region_x - 1]\n",
    "                    dy = gaussian_image[region_y - 1, region_x] - gaussian_image[region_y + 1, region_x]\n",
    "                    \n",
    "                    gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
    "                    gradient_orientation = rad2deg(arctan2(dy, dx))\n",
    "                    \n",
    "                    # Constant in front of exponential can be dropped since peaks will be found later\n",
    "                    weight = exp(weight_factor * (i ** 2 + j ** 2))  \n",
    "                    histogram_index = int(round(gradient_orientation * num_bins / 360.))\n",
    "                    raw_histogram[histogram_index % num_bins] += weight * gradient_magnitude\n",
    "  \n",
    "  # Iterate through number of histogram bins\n",
    "  for n in range(num_bins):\n",
    "        smooth_histogram[n] = (6 * raw_histogram[n] + 4 * (raw_histogram[n - 1] + raw_histogram[(n + 1) % num_bins]) + raw_histogram[n - 2] + raw_histogram[(n + 2) % num_bins]) / 16.\n",
    "  \n",
    "  orientation_max = max(smooth_histogram)\n",
    "  orientation_peaks = where(logical_and(smooth_histogram > roll(smooth_histogram, 1), smooth_histogram > roll(smooth_histogram, -1)))[0]\n",
    "  \n",
    "  # For each peak value in orientation_peaks\n",
    "  for peak_index in orientation_peaks:\n",
    "      peak_value = smooth_histogram[peak_index]\n",
    "      if peak_value >= peak_ratio * orientation_max:\n",
    "          # Quadratic peak interpolation\n",
    "          # The interpolation update is given by equation (6.30) in:\n",
    "          # https://ccrma.stanford.edu/~jos/sasp/Quadratic_Interpolation_Spectral_Peaks.html\n",
    "\n",
    "          left_value = smooth_histogram[(peak_index - 1) % num_bins]\n",
    "          right_value = smooth_histogram[(peak_index + 1) % num_bins]\n",
    "          interpolated_peak_index = (peak_index + 0.5 * (left_value - right_value) / (left_value - 2 * peak_value + right_value)) % num_bins\n",
    "          orientation = 360. - interpolated_peak_index * 360. / num_bins\n",
    "          if abs(orientation - 360.) < float_tolerance:\n",
    "              orientation = 0\n",
    "          new_keypoint = KeyPoint(*keypoint.pt, keypoint.size, orientation, keypoint.response, keypoint.octave)\n",
    "          keypoints_with_orientations.append(new_keypoint)\n",
    "  return keypoints_with_orientations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d616bc",
   "metadata": {},
   "source": [
    "## Duplicate Keypoint Removal Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea75ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns true if the first keypoint is \"less\" than the second\n",
    "# Used in the next function to remove duplicate keypoints\n",
    "def compareKeypoints(keypoint1, keypoint2):\n",
    "\n",
    "  # All attributes of the keypoints are compared\n",
    "  if keypoint1.pt[0] != keypoint2.pt[0]:\n",
    "    return keypoint1.pt[0] - keypoint2.pt[0]\n",
    "  if keypoint1.pt[1] != keypoint2.pt[1]:\n",
    "    return keypoint1.pt[1] - keypoint2.pt[1]\n",
    "  if keypoint1.size != keypoint2.size:\n",
    "    return keypoint2.size - keypoint1.size\n",
    "  if keypoint1.angle != keypoint2.angle:\n",
    "    return keypoint1.angle - keypoint2.angle\n",
    "  if keypoint1.response != keypoint2.response:\n",
    "    return keypoint2.response - keypoint1.response\n",
    "  if keypoint1.octave != keypoint2.octave:\n",
    "    return keypoint2.octave - keypoint1.octave\n",
    "  return keypoint2.class_id - keypoint1.class_id\n",
    "\n",
    "# Sorts the keypoints and then removes any duplicates\n",
    "def removeDuplicateKeypoints(keypoints):\n",
    "    # Checks if there is only 1 or no keypoints\n",
    "    if len(keypoints) < 2:\n",
    "        return keypoints\n",
    "    \n",
    "    # The sort method is called with a key pointing to the previous function.\n",
    "    # This allows the program to run the function on each element while it is sorting.\n",
    "    keypoints.sort(key=cmp_to_key(compareKeypoints))\n",
    "    unique_keypoints = [keypoints[0]]\n",
    "    \n",
    "    # Remove the duplicate keypoints\n",
    "    for next_keypoint in keypoints[1:]:\n",
    "        last_unique_keypoint = unique_keypoints[-1]\n",
    "        if last_unique_keypoint.pt[0] != next_keypoint.pt[0] or \\\n",
    "           last_unique_keypoint.pt[1] != next_keypoint.pt[1] or \\\n",
    "           last_unique_keypoint.size != next_keypoint.size or \\\n",
    "           last_unique_keypoint.angle != next_keypoint.angle:\n",
    "            unique_keypoints.append(next_keypoint)\n",
    "            \n",
    "    return unique_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387e750",
   "metadata": {},
   "source": [
    "## Keypoint Scale Conversion Function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc12297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the keypoint point, size, and octave to the size to the input image\n",
    "def convertKeypointsToInputImageSize(keypoints):\n",
    "\n",
    "  converted_keypoints = []\n",
    "\n",
    "  for keypoint in keypoints:\n",
    "    keypoint.pt = tuple(0.5 * array(keypoint.pt))\n",
    "    keypoint.size *= 0.5\n",
    "\n",
    "    # The \"~\" is the bitwise operator. It returns (-x) - 1 (e.g. ~4 = -5)\n",
    "    # The \"|\" operator is the union operator for sets, but here it is used\n",
    "    # as a standard binary operator <- CHECK!!!\n",
    "    keypoint.octave = (keypoint.octave & ~255) | ((keypoint.octave - 1) & 255)\n",
    "\n",
    "    # Add the newly converted keypoint to array\n",
    "    converted_keypoints.append(keypoint)\n",
    "  \n",
    "  return converted_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4804952",
   "metadata": {},
   "source": [
    "## Descriptor Generation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656e0f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute octave, layer, and scale from a keypoint\n",
    "def unpackOctave(keypoint):\n",
    "    octave = keypoint.octave & 255\n",
    "    layer = (keypoint.octave >> 8) & 255\n",
    "    if octave >= 128:\n",
    "        octave = octave | -128\n",
    "    scale = 1 / float32(1 << octave) if octave >= 0 else float32(1 << -octave)\n",
    "    return octave, layer, scale\n",
    "\n",
    "# Generates the descriptors for each keypoint\n",
    "def generateDescriptors(keypoints, gaussian_images, window_width=4, num_bins=8,\n",
    "                        scale_multiplier=3, descriptor_max_value=0.2):\n",
    "    \n",
    "    descriptors = []\n",
    "\n",
    "    # Iterate through each keypoint\n",
    "    for keypoint in keypoints:\n",
    "        \n",
    "        # Here, we will create a new gradient histogram for each\n",
    "        # keypoint. Then, we also calculate the gradient magnitude\n",
    "        # and orientation of each pixel.\n",
    "        \n",
    "        # Unpack the octave and begin histogram creation\n",
    "        octave, layer, scale = unpackOctave(keypoint)\n",
    "        gaussian_image = gaussian_images[octave + 1, layer]\n",
    "        num_rows, num_cols = gaussian_image.shape\n",
    "        point = round(scale * array(keypoint.pt)).astype('int')\n",
    "        bins_per_degree = num_bins / 360.\n",
    "        \n",
    "        # Work out the orientation\n",
    "        angle = 360. - keypoint.angle\n",
    "        cos_angle = cos(deg2rad(angle))\n",
    "        sin_angle = sin(deg2rad(angle))\n",
    "        weight_multiplier = -0.5 / ((0.5 * window_width) ** 2)\n",
    "        \n",
    "        # We don't actually \"draw\" the histograms, we simply keep track of the\n",
    "        # bin values and bin indexes.\n",
    "        row_bin_list = []\n",
    "        col_bin_list = []\n",
    "        magnitude_list = []\n",
    "        orientation_bin_list = []\n",
    "        \n",
    "        # The first two dimensions are increased by 2 to account for border effects\n",
    "        histogram_tensor = zeros((window_width + 2, window_width + 2, num_bins))   \n",
    "\n",
    "        # Descriptor window size (described by half_width) follows OpenCV convention\n",
    "        hist_width = scale_multiplier * 0.5 * scale * keypoint.size\n",
    "        \n",
    "        # sqrt(2) corresponds to diagonal length of a pixel\n",
    "        half_width = int(round(hist_width * sqrt(2) * (window_width + 1) * 0.5))\n",
    "        \n",
    "        # Ensure half_width lies within image\n",
    "        half_width = int(min(half_width, sqrt(num_rows ** 2 + num_cols ** 2)))     \n",
    "\n",
    "        # Calculating each pixel's (hence iteration) gradient magnitude and orientation\n",
    "        for row in range(-half_width, half_width + 1):\n",
    "            for col in range(-half_width, half_width + 1):\n",
    "                row_rot = col * sin_angle + row * cos_angle\n",
    "                col_rot = col * cos_angle - row * sin_angle\n",
    "                row_bin = (row_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                col_bin = (col_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                if row_bin > -1 and row_bin < window_width and col_bin > -1 and col_bin < window_width:\n",
    "                    window_row = int(round(point[1] + row))\n",
    "                    window_col = int(round(point[0] + col))\n",
    "                    if window_row > 0 and window_row < num_rows - 1 and window_col > 0 and window_col < num_cols - 1:\n",
    "                        dx = gaussian_image[window_row, window_col + 1] - gaussian_image[window_row, window_col - 1]\n",
    "                        dy = gaussian_image[window_row - 1, window_col] - gaussian_image[window_row + 1, window_col]\n",
    "                        gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
    "                        gradient_orientation = rad2deg(arctan2(dy, dx)) % 360\n",
    "                        weight = exp(weight_multiplier * ((row_rot / hist_width) ** 2 + (col_rot / hist_width) ** 2))\n",
    "                        row_bin_list.append(row_bin)\n",
    "                        col_bin_list.append(col_bin)\n",
    "                        magnitude_list.append(weight * gradient_magnitude)\n",
    "                        orientation_bin_list.append((gradient_orientation - angle) * bins_per_degree)\n",
    "\n",
    "        for row_bin, col_bin, magnitude, orientation_bin in zip(row_bin_list, col_bin_list, magnitude_list, orientation_bin_list):\n",
    "            \n",
    "            # Smoothing via trilinear interpolation\n",
    "            # Notations follows https://en.wikipedia.org/wiki/Trilinear_interpolation\n",
    "            # Note that we are really doing the inverse of trilinear interpolation here (we take the center value of the cube and distribute it among its eight neighbors)\n",
    "            row_bin_floor, col_bin_floor, orientation_bin_floor = floor([row_bin, col_bin, orientation_bin]).astype(int)\n",
    "            row_fraction, col_fraction, orientation_fraction = row_bin - row_bin_floor, col_bin - col_bin_floor, orientation_bin - orientation_bin_floor\n",
    "            if orientation_bin_floor < 0:\n",
    "                orientation_bin_floor += num_bins\n",
    "            if orientation_bin_floor >= num_bins:\n",
    "                orientation_bin_floor -= num_bins\n",
    "\n",
    "            c1 = magnitude * row_fraction\n",
    "            c0 = magnitude * (1 - row_fraction)\n",
    "            c11 = c1 * col_fraction\n",
    "            c10 = c1 * (1 - col_fraction)\n",
    "            c01 = c0 * col_fraction\n",
    "            c00 = c0 * (1 - col_fraction)\n",
    "            c111 = c11 * orientation_fraction\n",
    "            c110 = c11 * (1 - orientation_fraction)\n",
    "            c101 = c10 * orientation_fraction\n",
    "            c100 = c10 * (1 - orientation_fraction)\n",
    "            c011 = c01 * orientation_fraction\n",
    "            c010 = c01 * (1 - orientation_fraction)\n",
    "            c001 = c00 * orientation_fraction\n",
    "            c000 = c00 * (1 - orientation_fraction)\n",
    "\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, orientation_bin_floor] += c000\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c001\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, orientation_bin_floor] += c010\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c011\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, orientation_bin_floor] += c100\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c101\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, orientation_bin_floor] += c110\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c111\n",
    "\n",
    "        descriptor_vector = histogram_tensor[1:-1, 1:-1, :].flatten()  # Remove histogram borders\n",
    "        # Threshold and normalize descriptor_vector\n",
    "        threshold = norm(descriptor_vector) * descriptor_max_value\n",
    "        descriptor_vector[descriptor_vector > threshold] = threshold\n",
    "        descriptor_vector /= max(norm(descriptor_vector), float_tolerance)\n",
    "        # Multiply by 512, round, and saturate between 0 and 255 to convert from float32 to unsigned char (OpenCV convention)\n",
    "        descriptor_vector = round(512 * descriptor_vector)\n",
    "        descriptor_vector[descriptor_vector < 0] = 0\n",
    "        descriptor_vector[descriptor_vector > 255] = 255\n",
    "        descriptors.append(descriptor_vector)\n",
    "    return array(descriptors, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361d15e",
   "metadata": {},
   "source": [
    "## Main SIFT Function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2acd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the SIFT descriptors and keypoints for a given image\n",
    "def computeKeypointsAndDescriptors(image, sigma=1.6, num_intervals=3, assumed_blur=0.5, image_border_width=5):\n",
    "    \n",
    "    if (VERBOSE_MODE == True):\n",
    "        img_temp = image\n",
    "        image = image.astype('float32')\n",
    "        print(\"GENERATING BASE IMAGE...\")\n",
    "        base_image = generateBaseImage(image, sigma, assumed_blur)\n",
    "        print(\"OK!\")\n",
    "        print(\"COMPUTING OCTAVES...\")\n",
    "        num_octaves = computeOctaves(base_image.shape)\n",
    "        print(\"OK!\")\n",
    "        print(\"GENERATING KERNELS...\")\n",
    "        gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "        print(\"OK!\")\n",
    "        print(\"GENERATING GAUSSIAN IMAGES...\")\n",
    "        gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "        print(\"OK!\")\n",
    "        print(\"GENERATING DIFFERENCE OF GAUSSIAN IMAGES...\")\n",
    "        dog_images = generateDoGImages(gaussian_images)\n",
    "        print(\"OK!\")\n",
    "        print(\"ATTEMPTING TO FIND SCALE-SPACE EXTREMA... (PLEASE WAIT)\")\n",
    "        keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "        print(\"OK!\")\n",
    "        print(\"REMOVING DUPLICATE KEYPOINTS...\")\n",
    "        keypoints = removeDuplicateKeypoints(keypoints)\n",
    "        print(\"OK!\")\n",
    "        print(\"CONVERTING KEYPOINTS TO INPUT IMAGE SIZE...\")\n",
    "        keypoints = convertKeypointsToInputImageSize(keypoints)\n",
    "        print(\"OK!\")\n",
    "        print(keypoints)\n",
    "        print(\"GENERATING DESCRIPTORS...\")\n",
    "        descriptors = generateDescriptors(keypoints, gaussian_images)\n",
    "        print(\"OK!\")\n",
    "        print(\"DONE! RETURNING KEYPOINTS AND DESCRIPTORS... (PLEASE WAIT)\")\n",
    "        \n",
    "        return keypoints, descriptors\n",
    "    else:\n",
    "        img_temp = image\n",
    "        image = image.astype('float32')\n",
    "        base_image = generateBaseImage(image, sigma, assumed_blur)\n",
    "        num_octaves = computeOctaves(base_image.shape)\n",
    "        gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "        gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "        dog_images = generateDoGImages(gaussian_images)\n",
    "        keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "        keypoints = removeDuplicateKeypoints(keypoints)\n",
    "        keypoints = convertKeypointsToInputImageSize(keypoints)\n",
    "        descriptors = generateDescriptors(keypoints, gaussian_images)\n",
    "        \n",
    "        return keypoints, descriptors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70831f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('evo-vii.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# STEP 1\n",
    "# Gets keypoints and descriptors of a given image\n",
    "kp, desc = computeKeypointsAndDescriptors(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d6cbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yeet = cv2.drawKeypoints(img1, kp, img1, color=(255,0,0))\n",
    "\n",
    "cv2.imshow('yee', yeet)\n",
    "\n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form crashing)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535c212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
